model:
  model: xlm-roberta
  pretrained-model: xlm-roberta-base
  num_labels: 3
train:
  optimizer: AdamW
  lr: 6.0e-05
  eps: 1.0e-08
  batch_size: 16
  epochs: 20
  scheduler:
    name: ExponentialLR
    gamma: 0.1
predict:
  quantization: 0
  model_output_dir: outputs/2022-01-14/13-52-20/
data:
  path: data
build_features:
  path: data
  max_sequence_length: 256
  split_train: 0.8
  split_test: 0.1
  split_eval: 0.1
